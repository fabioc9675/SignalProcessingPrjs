{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of my first neural network\n",
    "\n",
    "## Feed Forward Back Propagation\n",
    "\n",
    "se creará una red neuronal feed forward back propagation con una capa de entrada, una capa oculta y una capa de salida\n",
    "\n",
    "retorpropagacion: https://www.youtube.com/watch?v=tIeHLnjs5U8\n",
    "\n",
    "backpropagation: https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd\n",
    "\n",
    "### Author\n",
    "\n",
    "Fabian Castaño [GitHub](https://www.github.com/fabioc9675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importacion de librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">var_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">var_2</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">var_6</th>\n",
       "      <th colspan=\"8\" halign=\"left\">var_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salida</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>14.334429</td>\n",
       "      <td>1.215704</td>\n",
       "      <td>11.23</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>14.355</td>\n",
       "      <td>15.0450</td>\n",
       "      <td>17.08</td>\n",
       "      <td>70.0</td>\n",
       "      <td>14.294286</td>\n",
       "      <td>...</td>\n",
       "      <td>3.30100</td>\n",
       "      <td>6.685</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.087214</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>4.519</td>\n",
       "      <td>4.9245</td>\n",
       "      <td>5.0940</td>\n",
       "      <td>5.22350</td>\n",
       "      <td>5.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>18.334286</td>\n",
       "      <td>1.439496</td>\n",
       "      <td>15.38</td>\n",
       "      <td>17.3300</td>\n",
       "      <td>18.720</td>\n",
       "      <td>19.1375</td>\n",
       "      <td>21.18</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.135714</td>\n",
       "      <td>...</td>\n",
       "      <td>4.43600</td>\n",
       "      <td>6.682</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.020600</td>\n",
       "      <td>0.253934</td>\n",
       "      <td>5.144</td>\n",
       "      <td>5.8775</td>\n",
       "      <td>5.9815</td>\n",
       "      <td>6.18775</td>\n",
       "      <td>6.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>11.873857</td>\n",
       "      <td>0.723004</td>\n",
       "      <td>10.59</td>\n",
       "      <td>11.2625</td>\n",
       "      <td>11.835</td>\n",
       "      <td>12.4250</td>\n",
       "      <td>13.37</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13.247857</td>\n",
       "      <td>...</td>\n",
       "      <td>5.46725</td>\n",
       "      <td>8.456</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.116400</td>\n",
       "      <td>0.162068</td>\n",
       "      <td>4.745</td>\n",
       "      <td>5.0020</td>\n",
       "      <td>5.0915</td>\n",
       "      <td>5.22850</td>\n",
       "      <td>5.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_1                                                               \\\n",
       "       count       mean       std    min      25%     50%      75%    max   \n",
       "salida                                                                      \n",
       "1       70.0  14.334429  1.215704  11.23  13.7500  14.355  15.0450  17.08   \n",
       "2       70.0  18.334286  1.439496  15.38  17.3300  18.720  19.1375  21.18   \n",
       "3       70.0  11.873857  0.723004  10.59  11.2625  11.835  12.4250  13.37   \n",
       "\n",
       "       var_2             ...    var_6        var_7                             \\\n",
       "       count       mean  ...      75%    max count      mean       std    min   \n",
       "salida                   ...                                                    \n",
       "1       70.0  14.294286  ...  3.30100  6.685  70.0  5.087214  0.263699  4.519   \n",
       "2       70.0  16.135714  ...  4.43600  6.682  70.0  6.020600  0.253934  5.144   \n",
       "3       70.0  13.247857  ...  5.46725  8.456  70.0  5.116400  0.162068  4.745   \n",
       "\n",
       "                                        \n",
       "           25%     50%      75%    max  \n",
       "salida                                  \n",
       "1       4.9245  5.0940  5.22350  5.877  \n",
       "2       5.8775  5.9815  6.18775  6.550  \n",
       "3       5.0020  5.0915  5.22850  5.491  \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de los datos de entrenamiento\n",
    "d_train = pd.read_csv(\"dataset/seeds_dataset.csv\")\n",
    "d_train.head(5)\n",
    "d_train.groupby('salida').describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacion de dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normDataset(x, val):\n",
    "    return x/val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>salida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>0.03465</td>\n",
       "      <td>0.02040</td>\n",
       "      <td>0.05877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.03505</td>\n",
       "      <td>0.01969</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.1485</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.05714</td>\n",
       "      <td>0.03242</td>\n",
       "      <td>0.04543</td>\n",
       "      <td>0.05314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>0.05438</td>\n",
       "      <td>0.03201</td>\n",
       "      <td>0.01717</td>\n",
       "      <td>0.05001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>0.05439</td>\n",
       "      <td>0.03199</td>\n",
       "      <td>0.03986</td>\n",
       "      <td>0.04738</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_1   var_2     var_3    var_4    var_5    var_6    var_7  salida\n",
       "0  0.1663  0.1546  0.008747  0.06053  0.03465  0.02040  0.05877       1\n",
       "1  0.1644  0.1525  0.008880  0.05884  0.03505  0.01969  0.05533       1\n",
       "2  0.1526  0.1485  0.008696  0.05714  0.03242  0.04543  0.05314       1\n",
       "3  0.1403  0.1416  0.008796  0.05438  0.03201  0.01717  0.05001       1\n",
       "4  0.1389  0.1402  0.008880  0.05439  0.03199  0.03986  0.04738       1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizacion\n",
    "d_train[['var_1', 'var_2','var_3','var_4','var_5','var_6','var_7']] = d_train[['var_1', 'var_2','var_3','var_4','var_5','var_6','var_7']].apply(\n",
    "    lambda x: normDataset(x,100))\n",
    "\n",
    "d_train.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste de la salida\n",
    "\n",
    "Se debe poner la salida como un vector onehot, es decir, un vector que tenga como longitud la cantidad de etiquetas posibles, y que a su vez la respuesta de cada uno solo vaya de 0 a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>pequena</th>\n",
       "      <th>mediana</th>\n",
       "      <th>grande</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.05314</td>\n",
       "      <td>0.02777</td>\n",
       "      <td>0.04471</td>\n",
       "      <td>0.05178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>0.05279</td>\n",
       "      <td>0.02687</td>\n",
       "      <td>0.06169</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.008335</td>\n",
       "      <td>0.05176</td>\n",
       "      <td>0.02719</td>\n",
       "      <td>0.02221</td>\n",
       "      <td>0.05132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>0.05267</td>\n",
       "      <td>0.02967</td>\n",
       "      <td>0.04421</td>\n",
       "      <td>0.05002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.008491</td>\n",
       "      <td>0.05386</td>\n",
       "      <td>0.02911</td>\n",
       "      <td>0.03260</td>\n",
       "      <td>0.05316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_1   var_2     var_3    var_4    var_5    var_6    var_7  pequena  \\\n",
       "205  0.1182  0.1340  0.008274  0.05314  0.02777  0.04471  0.05178        0   \n",
       "206  0.1121  0.1313  0.008167  0.05279  0.02687  0.06169  0.05275        0   \n",
       "207  0.1143  0.1313  0.008335  0.05176  0.02719  0.02221  0.05132        0   \n",
       "208  0.1249  0.1346  0.008658  0.05267  0.02967  0.04421  0.05002        0   \n",
       "209  0.1270  0.1371  0.008491  0.05386  0.02911  0.03260  0.05316        0   \n",
       "\n",
       "     mediana  grande  \n",
       "205        0       1  \n",
       "206        0       1  \n",
       "207        0       1  \n",
       "208        0       1  \n",
       "209        0       1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean data\n",
    "dataset = d_train.dropna()\n",
    "\n",
    "# convert categorical 'Origin' data into one-hot data\n",
    "origin = dataset.pop('salida')\n",
    "dataset['pequena'] = (origin == 1)*1\n",
    "dataset['mediana'] = (origin == 2)*1\n",
    "dataset['grande'] = (origin == 3)*1\n",
    "\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion de los datos\n",
    "\n",
    "agrupar los datos de entrenamiento y de validacion, separar las entradas de las salida y convertir las salidas en un vector de la forma [0,0,0] a paritr del dato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_x = dataset[['var_1', 'var_2','var_3','var_4','var_5','var_6','var_7']].to_numpy()\n",
    "d_train_y = dataset[['pequena','mediana','grande']].to_numpy()\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(d_train_x, d_train_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network creation\n",
    "\n",
    "creation of neural network class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class Layer, uniquely defines the attributes and functionalities of a layer e.g. size, activation function, weights etc.\n",
    "class Layer:\n",
    "    # Initializes the basic attributes of a single layer\n",
    "    def __init__(self, size, index, activation='sigmoid'):\n",
    "        self.size = size  # defines the number of stacked neurons in the layer\n",
    "        self.activation_func = activation  # defines the activation function that each neuron in the layer uses\n",
    "        self.layer_index = index  # defines the location of layer in the network\n",
    "        self.a = 0  # defines the output of the layer after running through activation\n",
    "        self.z = 0  # defines the input of layer to the activation function\n",
    "\n",
    "    # Weight initialization is very important or the we might see vanishing/exploding gradient problem\n",
    "    # We use Glroot Initialization technique to intialize our weights and biases\n",
    "    def init_weight(self, input_shape, output_shape):\n",
    "        mean = 0\n",
    "        std = np.sqrt(2/(input_shape + output_shape))\n",
    "        self.weights = np.float32(\n",
    "            np.random.uniform(-std, std, (output_shape, input_shape)))\n",
    "        self.bias = np.float32(np.random.uniform(-std, std, (output_shape, 1)))\n",
    "\n",
    "    # return the output of layer after running the input through selected activation function\n",
    "    def activation(self, inputs):\n",
    "        self.z = np.dot(self.weights, inputs) + self.bias\n",
    "        self.a = 1/(1 + np.exp(-self.z))\n",
    "        return self.a\n",
    "\n",
    "    # provides the derivative of activation function for the current output of the layer\n",
    "    def activation_grad(self):\n",
    "        return self.a * (1 - self.a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Neural Network, defines multiple layers and runs forwad and back propogation to train the network.\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # defines the shape of Network and initializes layers\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        self.layers = list()\n",
    "        self.log_loss_hist = list()\n",
    "        j = 0\n",
    "        for i in shape:\n",
    "            self.layers.append(Layer(i,j))\n",
    "            j = j + 1\n",
    "    \n",
    "    # Initializes the weights and biases of our network for each layer\n",
    "    def initialize(self, X, y):\n",
    "        for i in range(len(self.layers)):\n",
    "            if i == 0:\n",
    "                self.layers[i].init_weight(X.shape[1], self.layers[i].size)\n",
    "            else:\n",
    "                self.layers[i].init_weight(self.layers[i-1].size, self.layers[i].size)\n",
    "\n",
    "    # performs forward propogation\n",
    "    def forward_propogation(self, X):\n",
    "        a = X.T\n",
    "        for layer in self.layers:\n",
    "            a = layer.activation(a)\n",
    "    \n",
    "    # calculates log logs and return the result\n",
    "    def loss(self, outputs, y):\n",
    "        lb = LabelBinarizer()\n",
    "        y_lb = lb.fit_transform(y)\n",
    "        outputs_lb = lb.transform(outputs)\n",
    "        loss = log_loss(y_lb, outputs_lb)\n",
    "        return loss\n",
    "\n",
    "    # Performs the most critical, Backpropogation to calculate delta values for each layer\n",
    "    def backpropogate(self, X, y):\n",
    "        delta = list()\n",
    "        delta_w = [0 for _ in range(len(self.layers))]\n",
    "        delta_b = [0 for _ in range(len(self.layers))]\n",
    "        error_o = (self.layers[-1].z - y.T)\n",
    "        for i in reversed(range(len(self.layers) - 1)):\n",
    "            error_i = np.multiply(self.layers[i+1].weights.T.dot(error_o), self.layers[i].activation_grad())\n",
    "            delta_w[i+1] = error_o.dot(self.layers[i].a.T)/len(y)\n",
    "            delta_b[i+1] = np.sum(error_o, axis=1, keepdims=True)/len(y)\n",
    "            error_o = error_i\n",
    "        delta_w[0] = error_o.dot(X)/len(y)\n",
    "        delta_b[0] = np.sum(error_o, axis=1, keepdims=True)/len(y)\n",
    "        return (delta_w, delta_b)\n",
    "\n",
    "    # Uses the delta values to update weights and biases\n",
    "    def update_weights_bias(self, delta_w, delta_b, lr):\n",
    "        #print(self.layers[0].bias.shape)\n",
    "        for i in range(len(self.layers)):\n",
    "            layer = self.layers[i]\n",
    "            layer.weights = layer.weights - (lr*delta_w[i])\n",
    "            layer.bias = layer.bias - (lr*delta_b[i]) \n",
    "\n",
    "    # Used to orchestrate the training of network, given a certain epoch and learning rate\n",
    "    def train(self, X, y, epochs, batch_size, lr):\n",
    "        self.initialize(X, y)\n",
    "        lb = LabelBinarizer()\n",
    "        y_lb = lb.fit_transform(y)\n",
    "        y_lb = lb.fit_transform(y)\n",
    "        for i in range(epochs):\n",
    "            low = 0\n",
    "            high = low + batch_size\n",
    "            self.log_loss_hist.append(self.loss(np.argmax(self.predict(X), axis=0), y))\n",
    "            while(low < X.shape[0]):\n",
    "                X_bat = X[low:high,:]\n",
    "                y_bat = y_lb[low:high]\n",
    "                self.forward_propogation(X_bat)\n",
    "                outputs = self.layers[-1].a\n",
    "                delta_w, delta_b = self.backpropogate(X_bat, y_bat)\n",
    "                self.update_weights_bias(delta_w, delta_b, lr)\n",
    "                low = high\n",
    "                if (low + batch_size) > X.shape[0]:\n",
    "                    high = X.shape[0]\n",
    "                else:\n",
    "                    high = low + batch_size\n",
    "\n",
    "    # Runs the input through the network and returns\n",
    "    def predict(self, X):\n",
    "        a = X.T\n",
    "        for layer in self.layers:\n",
    "            a = layer.activation(a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation and training\n",
    "\n",
    "Creation of the model to predict seeds distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and its architecture\n",
    "model = NeuralNetwork((5,5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model using the hyper-parameters\n",
    "model.train(x_train, y_train, 2000, 5, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(model.log_loss_hist))), model.log_loss_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation process\n",
    "\n",
    "validate the Neural Network working with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 88.89\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction on test data and measure performance\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_test_out = np.argmax(y_test, axis=1)\n",
    "y_pred_out = np.argmax(y_pred, axis=0)\n",
    "\n",
    "print(f\"Accuracy Score: {np.round(accuracy_score(y_test_out, y_pred_out)*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 1, target: 1\n",
      "predict: 0, target: 0\n",
      "predict: 0, target: 1\n",
      "predict: 1, target: 1\n",
      "predict: 0, target: 1\n",
      "predict: 0, target: 0\n",
      "predict: 0, target: 1\n",
      "predict: 2, target: 2\n",
      "predict: 0, target: 0\n",
      "predict: 1, target: 1\n"
     ]
    }
   ],
   "source": [
    "# print some data test\n",
    "for i in range(10):\n",
    "    print(f\"predict: {y_pred_out[i]}, target: {y_test_out[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion de un dato\n",
    "\n",
    "este dato debe dar en la tercera neurona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49639887],\n",
       "       [0.50593954],\n",
       "       [0.72928171]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = np.array([12.22,13.32,0.8652,5.224,2.967,5.469,5.221],dtype = float)/100\n",
    "# x_val = x_test[2]\n",
    "x_val = x_val.reshape((1,7))\n",
    "print(x_val.shape)\n",
    "model.predict(x_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
